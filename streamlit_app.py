import streamlit as st
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import torch
from pydub import AudioSegment
import librosa
import os

# ØªØ§Ø¨Ø¹ ØªØ¨Ø¯ÛŒÙ„ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ ÙØ±Ù…Øª WAV
def convert_to_wav(input_audio_path):
    file_name, file_extension = os.path.splitext(input_audio_path)
    if file_extension.lower() != ".wav":
        output_audio_path = file_name + ".wav"
        audio = AudioSegment.from_file(input_audio_path)
        audio.export(output_audio_path, format="wav")
        return output_audio_path
    else:
        return input_audio_path

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„ Ùˆ Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´
model_path = "C:/Users/FZL/Downloads/whisper"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Whisper Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ù†Ø¯Ù‡
model = WhisperForConditionalGeneration.from_pretrained(model_path).to(device)
processor = WhisperProcessor.from_pretrained(model_path)

# Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Streamlit
st.set_page_config(page_title="ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ†", page_icon=":sound:", layout="wide")

# Ø§Ø¹Ù…Ø§Ù„ CSS Ø¨Ø±Ø§ÛŒ ÙˆØ³Ø·â€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ Ùˆ Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù…ØªÙ†
st.markdown("""
    <style>
    /* ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø±Ø§ÛŒ ÙˆØ³Ø· Ú†ÛŒÙ† Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡ */
    .main {
        display: flex;
        justify-content: center;
        align-items: center;
        padding-top: 50px;
        text-align: center;
    }

    /* ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ù…ØªÙ†â€ŒÙ‡Ø§ */
    .rtl-text {
        direction: rtl;
        text-align: right;
        font-size: 18px;
        font-family: "IRANSans", sans-serif;
    }

    </style>
    """, unsafe_allow_html=True)

# Ù‡Ø¯Ø±
st.image("https://your-image-url.com/banner.png", use_column_width=True)
st.title("ğŸ”Š ØªØ¨Ø¯ÛŒÙ„ ØµÙˆØª Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Whisper")

st.markdown("""
    Ø§ÛŒÙ† Ø§Ø¨Ø²Ø§Ø± Ø¨Ù‡ Ø´Ù…Ø§ Ø§Ù…Ú©Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†ÛŒØ¯. 
    Ú©Ø§ÙÛŒØ³Øª ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ ÙØ±Ù…Øª **WAV**, **MP3**, **OGG** ÛŒØ§ **FLAC** Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ù…ØªÙ† Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒØ¯.
    """)

# Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
st.markdown("### 1ï¸âƒ£ Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ")
audio_file = st.file_uploader("ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", type=["wav", "mp3", "ogg", "flac"])

if audio_file is not None:
    # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ù…ÙˆÙ‚Øª
    with open("temp_audio_file", "wb") as f:
        f.write(audio_file.getbuffer())

    # Ù†Ø´Ø§Ù†Ú¯Ø± Ù¾ÛŒØ´Ø±ÙØª
    with st.spinner('Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ...'):
        # ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª WAV (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
        wav_audio_file = convert_to_wav("temp_audio_file")

        # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ librosa Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
        audio, sampling_rate = librosa.load(wav_audio_file, sr=16000)

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Whisper
        audio_input = processor(audio, sampling_rate=sampling_rate, return_tensors="pt").input_features.to(device)

        # ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† Ø§Ø² ØµÙˆØª
        predicted_ids = model.generate(audio_input)
        transcribed_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]

        # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª Ù¾Ø³ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´
        os.remove("temp_audio_file")

    # Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¯Ø± Ø­Ø§Ù„Øª Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†
    st.markdown("### 2ï¸âƒ£ Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:")
    st.markdown(f"<div class='rtl-text'>{transcribed_text}</div>", unsafe_allow_html=True)

    # Ø¯Ú©Ù…Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ØªÙ†
    st.markdown("### 3ï¸âƒ£ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ØªÙ†:")
    st.download_button(label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ØªÙ†", data=transcribed_text, file_name="transcription.txt", mime="text/plain")

else:
    st.warning("Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
